# 🎭 DeepFake Video Detection Project

A deep learning-based solution to detect deepfake content in videos and audio using multiple specialized models. The system is designed to differentiate between real and synthetic media by analyzing both visual frames and audio spectrograms.

---

## 📌 About the Project

This project is a combination of multiple deep learning models working together to identify deepfake content in multimedia files. It processes both **video frames** and **audio signals** to determine authenticity.

---

## 🧠 Models Used

### 🎧 Audio Testing Model
- Converts the audio signal into **spectrogram images**.
- Applies a **Convolutional Neural Network (CNN)** to analyze audio patterns and classify them as real or fake.
  
### 🎥 Video Testing Models

1. **CNN Model**
   - Analyzes individual frames of the video.
   - Detects visual inconsistencies that are typical in deepfake videos.

2. **LSTM & RNN Model**
   - Processes sequential frames.
   - Detects temporal anomalies or irregular motion patterns in video streams.

3. **GAN Model**
   - Detects images generated by deepfake generators.
   - Classifies frames based on whether they have been synthesized using GANs.

---

## 🛠️ Technologies Used

- Python
- TensorFlow
- Torch
- OpenCV
- Librosa
- NumPy / Pandas
- Matplotlib

---

## 🧪 How It Works

### 🔍 For Video Identification:
- Extracts frames from the video file.
- Feeds the frames into CNN, LSTM/RNN, and GAN-based models for analysis.
- Final decision is based on combined model outputs.

![image](https://github.com/user-attachments/assets/7b98519c-3c7c-4b7c-93b8-1acc138effa4)

---

### 🔉 For Audio Identification:
- Converts audio from the video into a **mel spectrogram**.
- Uses a CNN to classify the spectrogram as deepfake or real.
- Useful for catching voice cloning or AI-generated audio mismatches.

![image](https://github.com/user-attachments/assets/9d82f5c2-cbe8-4328-af43-5a51037c6ef1)


